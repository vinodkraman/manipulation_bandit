# pull each arm once
for i in range(K):
    reward = nature.generate_reward(i)
    for bandit in bandits:
        bandit.update_arm(i, reward)

#run bandit
for bandit in bandits:
    # bandit.reset()
    for experiment in range(num_experiments):
        for t in range(T):
                arm = bandit.select_arm(t+1)
                regret = nature.compute_per_round_regret(arm)
                total_regret[bandit][experiment] += regret
                cumulative_regret_history[bandit][experiment][t] = total_regret[bandit][experiment]/(t+1)
                reward = nature.generate_reward(arm)
                bandit.update_arm(arm, reward)

#average over experiments
average_cumulative_regret_history = {i:np.zeros(T) for i in bandits}
for (bandit, experiments) in cumulative_regret_history.items():
    sum_regret = np.zeros(T)
    for (experiment_num, regret) in experiments.items():
        sum_regret += regret

    sum_regret /= num_experiments
    average_cumulative_regret_history[bandit] = sum_regret

#plot
for (key, value) in average_cumulative_regret_history.items():
    plt.plot(average_cumulative_regret_history[key], label=key_map[key])